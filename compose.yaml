services:
  # HDFS NameNode (master)
  namenode:
    image: matnar/hadoop
    hostname: master
    container_name: namenode
    tty: true         # interactive
    stdin_open: true  # stdin open
    ports:
      - 9870:9870 # web-ui
    volumes:
      - ./data:/app/data        # folder containing the dataset
      - ./Results:/app/results  # folder for the results
    # it waits for the DataNodes to start
    depends_on:
      - datanode-1
      - datanode-2
      - datanode-3
  # HDFS DataNodes
  datanode-1:
    image: matnar/hadoop
    container_name: datanode-1
    hostname: slave1
    tty: true
    stdin_open: true
  datanode-2:
    image: matnar/hadoop
    container_name: datanode-2
    hostname: slave2
    tty: true
    stdin_open: true
  datanode-3:
    image: matnar/hadoop
    container_name: datanode-3
    hostname: slave3
    tty: true
    stdin_open: true
  # Spark Master node
  spark-master:
    image: spark:python3
    container_name: spark-master
    hostname: spark-master
    command: /bin/bash
    tty: true
    stdin_open: true
    ports:
      - 8080:8080 # web-ui
      - 4040:4040 # web-ui
    depends_on:
      - namenode
    environment:
      SPARK_LOCAL_IP: spark-master
      MONGO_USERNAME: ${MONGO_USERNAME}
      MONGO_PASSWORD: ${MONGO_PASSWORD}
      MONGO_DATABASE: ${MONGO_DATABASE}
    volumes:
      - ./src/:/app/
  # Spark Worker nodes
  spark-worker-1:
    image: spark:python3
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: /bin/bash
    tty: true
    stdin_open: true
    environment:
      MONGO_USERNAME: ${MONGO_USERNAME}
      MONGO_PASSWORD: ${MONGO_PASSWORD}
      MONGO_DATABASE: ${MONGO_DATABASE}
    depends_on:
      - spark-master
  spark-worker-2:
    image: spark:python3
    container_name: spark-worker-2
    hostname: spark-worker-2
    command: /bin/bash
    tty: true
    stdin_open: true
    environment:
      MONGO_USERNAME: ${MONGO_USERNAME}
      MONGO_PASSWORD: ${MONGO_PASSWORD}
      MONGO_DATABASE: ${MONGO_DATABASE}
    depends_on:
      - spark-master
  # Data Ingestion
  nifi:
    image: apache/nifi
    container_name: nifi
    hostname: nifi
    environment:
      SINGLE_USER_CREDENTIALS_USERNAME: ${NIFI_USERNAME}
      SINGLE_USER_CREDENTIALS_PASSWORD: ${NIFI_PASSWORD}
    ports:
      - 8443:8443
    volumes:
      - ./nifi/hdfs:/data
    depends_on:
      - namenode
  mongo:
    image: mongo
    container_name: mongo
    hostname: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    depends_on:
      - spark-master
  mongo-express:
    image: mongo-express
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_USERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_PASSWORD}
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@mongo:27017/
      ME_CONFIG_BASICAUTH: false
